# test_dpq_integration.py - Complete DPQ workflow test

import json
import sys
import os
from datetime import datetime

# Add the dpq directory directly to the path
dpq_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'dpq')
sys.path.insert(0, dpq_path)

# Import the modules directly using the correct class names
from dpq import dpq as dpq_module
from dpq import response_formatter as rf_module

def safe_format_number(value, decimals=2):
    """Safely format a number, handling both numeric and string types"""
    try:
        if isinstance(value, str):
            # Try to convert string to float
            num_value = float(value)
            return f"{num_value:.{decimals}f}"
        elif isinstance(value, (int, float)):
            return f"{value:.{decimals}f}"
        else:
            return str(value)
    except (ValueError, TypeError):
        return str(value)

def make_json_serializable(obj):
    """Convert object to JSON-serializable format"""
    if isinstance(obj, dict):
        return {key: make_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [make_json_serializable(item) for item in obj]
    elif isinstance(obj, bool):
        return obj  # booleans are actually JSON serializable in Python
    elif isinstance(obj, (int, float, str, type(None))):
        return obj
    else:
        return str(obj)  # Convert anything else to string

def test_complete_dpq_workflow():
    """
    Test the complete DPQ workflow from frontend input to JSON output
    """
    
    # Example frontend input (what would come from the mobile app)
    frontend_input = {
        "user_id": "user_12345",
        "dog_info": {
            "name": "Max",
            "birthday": "2020-03-15T00:00:00Z",
            "breed": "Golden Retriever"
        },
        "assessment_metadata": {
            "started_at": "2024-01-15T10:30:00Z",
            "completed_at": "2024-01-15T10:45:00Z",
            "assessment_duration_minutes": 15,
            "device_type": "iOS",
            "app_version": "1.2.3"
        },
        "responses": {
            "1": 6, "2": 5, "3": 4, "4": 6, "5": 3,
            "6": 5, "7": 6, "8": 4, "9": 5, "10": 6,
            "11": 3, "12": 4, "13": 5, "14": 6, "15": 4,
            "16": 5, "17": 3, "18": 6, "19": 4, "20": 5,
            "21": 6, "22": 4, "23": 5, "24": 3, "25": 6,
            "26": 5, "27": 4, "28": 6, "29": 3, "30": 5,
            "31": 4, "32": 6, "33": 5, "34": 4, "35": 3,
            "36": 6, "37": 5, "38": 4, "39": 6, "40": 3,
            "41": 5, "42": 4, "43": 6, "44": 5, "45": 4
        }
    }
    
    print("=== DPQ Complete Integration Test ===")
    print(f"Testing with dog: {frontend_input['dog_info']['name']}")
    print(f"Number of responses: {len(frontend_input['responses'])}")
    print(f"DPQ path: {dpq_path}")
    
    try:
        # Step 1: Initialize DPQ using the correct class name
        dpq = dpq_module.DogPersonalityQuestionnaire()
        print("‚úì DogPersonalityQuestionnaire initialized successfully")
        
        # Step 2: Score the assessment - convert string keys to integers
        responses_int = {int(k): v for k, v in frontend_input['responses'].items()}
        dpq_results = dpq.score_assessment(responses_int, dog_id=frontend_input['dog_info']['name'])
        print("‚úì Assessment scored successfully")
        print(f"  Factor scores: {list(dpq_results.factor_scores.keys())}")
        
        # Step 3: Initialize response formatter
        formatter = rf_module.DPQResponseFormatter()
        print("‚úì Response formatter initialized")
        
        # Step 4: Convert DPQResults to the format expected by the formatter
        # The formatter expects a dictionary format, so we'll convert the dataclass
        dpq_results_dict = {
            'factor_scores': dpq_results.factor_scores,
            'facet_scores': dpq_results.facet_scores,
            'personality_profile': dpq_results.personality_profile,
            'bias_indicators': dpq_results.bias_indicators,
            'raw_scores': dpq_results.raw_scores
        }
        
        # Step 5: Format complete response
        complete_response = formatter.format_assessment_response(
            dpq_results=dpq_results_dict,
            dog_info=frontend_input['dog_info'],
            user_id=frontend_input['user_id'],
            assessment_metadata=frontend_input['assessment_metadata'],
            responses=frontend_input['responses']
        )
        print("‚úì Response formatted successfully")
        
        # Step 6: Display results
        print("\n=== RESULTS ===")
        print(f"Assessment ID: {complete_response['assessment_id']}")
        print(f"Dog: {complete_response['dog_info']['name']}")
        
        print("\nPersonality Factors:")
        for factor, data in complete_response['personality_factors'].items():
            score_str = safe_format_number(data['score'])
            print(f"  {factor}: {score_str} ({data['level']})")
        
        print("\nAI Bias Indicators:")
        for indicator, value in complete_response['ai_bias_indicators'].items():
            value_str = safe_format_number(value, 3)
            print(f"  {indicator}: {value_str}")
        
        print("\nPersonality Summary:")
        print(f"  Primary Type: {complete_response['personality_summary']['primary_type']}")
        dominant_traits = complete_response['personality_summary']['dominant_traits']
        if dominant_traits:
            print(f"  Dominant Traits: {', '.join(dominant_traits)}")
        else:
            print("  Dominant Traits: None identified")
        
        print("\nAI Translator Config:")
        print(f"  Communication Style: {complete_response['ai_translator_config']['communication_style']}")
        print(f"  Base Energy Level: {complete_response['ai_translator_config']['tone_adjustments']['base_energy_level']}")
        
        print("\nRecommendations:")
        if complete_response['recommendations'].get('training_tips'):
            print("  Training Tips:")
            for tip in complete_response['recommendations']['training_tips']:
                print(f"    - {tip}")
        else:
            print("  Training Tips: None provided")
        
        if complete_response['recommendations'].get('exercise_needs'):
            print("  Exercise Needs:")
            for need in complete_response['recommendations']['exercise_needs']:
                print(f"    - {need}")
        else:
            print("  Exercise Needs: None provided")
        
        print("\nQuality Metrics:")
        reliability_score = safe_format_number(complete_response['quality_metrics']['reliability_score'])
        response_consistency = safe_format_number(complete_response['quality_metrics']['response_consistency'])
        print(f"  Reliability Score: {reliability_score}")
        print(f"  Response Consistency: {response_consistency}")
        print(f"  All Questions Answered: {complete_response['quality_metrics']['all_questions_answered']}")
        
        # Step 7: Save complete JSON output with proper serialization
        output_filename = f"dpq_complete_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # Make the response JSON serializable
        json_safe_response = make_json_serializable(complete_response)
        
        try:
            with open(output_filename, 'w') as f:
                json.dump(json_safe_response, f, indent=2, ensure_ascii=False)
            print(f"\n‚úì Complete JSON output saved to: {output_filename}")
        except Exception as json_error:
            print(f"‚ùå JSON serialization failed: {json_error}")
            print("Attempting to save with string conversion...")
            
            # Fallback: convert problematic values to strings
            def convert_to_strings(obj):
                if isinstance(obj, dict):
                    return {key: convert_to_strings(value) for key, value in obj.items()}
                elif isinstance(obj, list):
                    return [convert_to_strings(item) for item in obj]
                elif isinstance(obj, bool):
                    return str(obj).lower()  # Convert boolean to string
                else:
                    return obj
            
            string_safe_response = convert_to_strings(complete_response)
            with open(output_filename, 'w') as f:
                json.dump(string_safe_response, f, indent=2, ensure_ascii=False)
            print(f"‚úì JSON output saved with string conversion: {output_filename}")
        
        # Step 8: Validate JSON structure
        print("\n=== JSON VALIDATION ===")
        required_fields = [
            'assessment_id', 'dog_id', 'user_id', 'dog_info', 'responses',
            'personality_factors', 'ai_bias_indicators', 'personality_summary',
            'ai_translator_config', 'recommendations', 'quality_metrics', 'metadata'
        ]
        
        missing_fields = [field for field in required_fields if field not in complete_response]
        if missing_fields:
            print(f"‚ùå Missing required fields: {missing_fields}")
        else:
            print("‚úì All required fields present")
        
        # Validate personality factors structure
        all_factors_valid = True
        for factor_name, factor_data in complete_response['personality_factors'].items():
            required_factor_fields = ['score', 'level', 'description']
            missing_factor_fields = [field for field in required_factor_fields if field not in factor_data]
            if missing_factor_fields:
                print(f"‚ùå Factor {factor_name} missing fields: {missing_factor_fields}")
                all_factors_valid = False
        
        if all_factors_valid:
            print("‚úì Personality factors structure valid")
        
        # Test JSON serialization
        try:
            json_string = json.dumps(json_safe_response, ensure_ascii=False)
            print("‚úì JSON serialization successful")
            print(f"  JSON size: {len(json_string)} characters")
        except Exception as e:
            print(f"‚ùå JSON serialization failed: {e}")
        
        # Step 9: Display detailed analysis
        print("\n=== DETAILED ANALYSIS ===")
        print("\nFactor Analysis:")
        for factor, data in complete_response['personality_factors'].items():
            print(f"\n{factor}:")
            print(f"  Score: {safe_format_number(data['score'])}")
            print(f"  Level: {data['level']}")
            print(f"  Description: {data['description']}")
        
        print("\n=== TEST COMPLETED SUCCESSFULLY ===")
        return complete_response
        
    except Exception as e:
        print(f"‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return None

def test_edge_cases():
    """
    Test edge cases and error handling
    """
    print("\n=== TESTING EDGE CASES ===")
    
    # Test with minimal responses
    minimal_input = {
        "user_id": "user_test",
        "dog_info": {
            "name": "TestDog"
        },
        "assessment_metadata": {
            "started_at": datetime.now().isoformat() + "Z",
            "completed_at": datetime.now().isoformat() + "Z"
        },
        "responses": {str(i): 4 for i in range(1, 46)}  # All neutral responses
    }
    
    try:
        dpq = dpq_module.DogPersonalityQuestionnaire()
        responses_int = {int(k): v for k, v in minimal_input['responses'].items()}
        dpq_results = dpq.score_assessment(responses_int, dog_id=minimal_input['dog_info']['name'])
        
        formatter = rf_module.DPQResponseFormatter()
        
        # Convert DPQResults to dictionary format
        dpq_results_dict = {
            'factor_scores': dpq_results.factor_scores,
            'facet_scores': dpq_results.facet_scores,
            'personality_profile': dpq_results.personality_profile,
            'bias_indicators': dpq_results.bias_indicators,
            'raw_scores': dpq_results.raw_scores
        }
        
        response = formatter.format_assessment_response(
            dpq_results=dpq_results_dict,
            dog_info=minimal_input['dog_info'],
            user_id=minimal_input['user_id'],
            assessment_metadata=minimal_input['assessment_metadata'],
            responses=minimal_input['responses']
        )
        
        print("‚úì Edge case test passed - neutral responses")
        print(f"  Primary type: {response['personality_summary']['primary_type']}")
        
    except Exception as e:
        print(f"‚ùå Edge case test failed: {e}")
        import traceback
        traceback.print_exc()

def main():
    """
    Run all tests
    """
    print("Starting DPQ Complete Integration Tests...\n")
    
    # Test 1: Complete workflow
    result = test_complete_dpq_workflow()
    
    # Test 2: Edge cases
    test_edge_cases()
    
    if result:
        print("\nüéâ All tests completed successfully!")
        print("\nThe complete JSON response is ready for frontend integration.")
        print("\nKey features tested:")
        print("  ‚úì DPQ scoring algorithm")
        print("  ‚úì Response formatting")
        print("  ‚úì AI bias indicators")
        print("  ‚úì AI translator configuration")
        print("  ‚úì Personality summaries")
        print("  ‚úì Recommendations generation")
        print("  ‚úì JSON serialization (with fallback)")
        print("  ‚úì Database-ready format")
        print("\nNext steps:")
        print("  1. Review the generated JSON output file")
        print("  2. Integrate with your mobile app API")
        print("  3. Test with real user data")
        print("  4. Deploy to production environment")
    else:
        print("\n‚ùå Tests failed - check errors above")

if __name__ == "__main__":
    main()
